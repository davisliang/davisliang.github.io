---
layout: page
permalink: /XLM-V/
title: XLM-V
nav: true
---

We are releasing XLM-V, a multilingual model with a 1 million token vocabulary. XLM-V outperforms XLM-R on every multilingual task we tested it on (XNLI, MLQA, TyDiQA, XQuAD, WikiAnn) with outsized gains on low-resource language tasks (MasakhaNER, AmericasNLI). [[Paper]](https://arxiv.org/abs/2301.10472) [[Download]](https://dl.fbaipublicfiles.com/fairseq/xlmv/xlmv.base.tar.gz) [[Instructions]](https://github.com/davisliang/fairseq/tree/main/examples/xlmv)
